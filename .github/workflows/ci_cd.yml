#CI_CD Pipeline: The ci_cd.yml file is the master blueprint for the entire 
#MLOps workflow. It orchestrates all stages in a single continuous process.
#Phase Name,                    YAML Stage,           Purpose,                                                                                                       Primary Output
#1. Continuous Integration (CI)->Setup and Installation->Prepares the isolated runner environment by installing dependencies and creating the train_sentiment script via setup.py.,->Functional Python Environment
#2. Continuous Training (CT)->Run Model Training->"Executes the train_sentiment script to train the model, evaluate it, and log it persistently to MLflow.",  ->MLflow Model Artifact (The trained model)
#3. Continuous Delivery (CD)->Build and Push Docker Image,->"Packages the inference code (predict.py), its dependencies, and the serving configuration into an isolated, versioned artifact.",-> Docker Image (The production serving container)
#The ci_cd.yml file is responsible for the training (CI/CT) and for the creation of the deployment asset (CD).
#Think of it this way: That is an extremely crucial point to clarify! You've noticed a potential contradiction in the terminology.You are absolutely correct that the ci_cd.yml file is primarily focused on the Continuous Integration (CI) and Continuous Training/Delivery (CD) stages, starting with setup and installation (pip install -e .) and running the training (train_sentiment).The confusion arose because the ultimate goal of the entire pipeline, as defined in that file, is to produce a deployable asset used for Inference/Serving.Here is the corrected explanation of the two distinct roles within that single YAML file:The Two Roles of ci_cd.ymlThe ci_cd.yml file is the master blueprint for the entire MLOps workflow. It orchestrates all stages in a single continuous process.Phase NameYAML StagePurposePrimary Output1. Continuous Integration (CI)Setup and InstallationPrepares the isolated runner environment by installing dependencies and creating the train_sentiment script via setup.py.Functional Python Environment2. Continuous Training (CT)Run Model TrainingExecutes the train_sentiment script to train the model, evaluate it, and log it persistently to MLflow.MLflow Model Artifact (The trained model)3. Continuous Delivery (CD)Build and Push Docker ImagePackages the inference code (predict.py), its dependencies, and the serving configuration into an isolated, versioned artifact.Docker Image (The production serving container)Correcting the MisconceptionThe ci_cd.yml file is responsible for the training (CI/CT) and for the creation of the deployment asset (CD).The reason we focus so much on the Docker image is that the image itself is the package that contains the inference code. Once that image is deployed, it performs inference for the end-user.Think of it this way:CI/CT Steps: The factory floor where the product (the trained model) is made.CD Steps: The packaging line where the delivery box (the Docker image) is created to securely ship the product to the store (deployment environment).ShutterstockExploreThe ci_cd.yml defines both the factory floor and the packaging line in one seamless script.
  #CI/CT Steps: The factory floor where the product (the trained model) is made.
  #CD Steps: The packaging line where the delivery box (the Docker image) is created 
    #to securely ship the product to the store (deployment environment).

name: MLOps CI/CD Pipeline (Train, Promote, Package)

on:
  push:
    branches:
      - main # Trigger the pipeline on pushes to the main branch

# Define environment variables for the entire workflow
env:
  # These must be set as secrets in GitHub for remote MLflow tracking
  MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
  MLFLOW_TRACKING_USERNAME: ${{ secrets.MLFLOW_USERNAME }}
  MLFLOW_TRACKING_PASSWORD: ${{ secrets.MLFLOW_PASSWORD }}
  AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }} # For S3 artifact store
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  
jobs:
  mlops_pipeline:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout Repository Code
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          
      # --- CI STAGE: Setup and Installation ---
      - name: Install Project and Dependencies
        run: pip install -e .

      # ðŸ’¥ CRITICAL FIX 1: Download NLTK data explicitly into the runner's workspace
      - name: Download NLTK Resources
        run: |
          # Set the environment variable to a known location for all subsequent steps
          echo "NLTK_DATA=/home/runner/nltk_data" >> $GITHUB_ENV
          
          # Force download necessary resources into that location before training starts
          python -c "import nltk; nltk.download(['stopwords', 'wordnet', 'punkt'], download_dir='/home/runner/nltk_data')"

      # ðŸ’¥ CRITICAL FIX 2: Ensure Data is in the correct subfolder
      - name: Prepare Data Directory
        run: |
          mkdir -p data
          # CRITICAL FIX: Copy the committed CSV file from the root (where Git checks it out) 
          # to the 'data/' subfolder (where train_model.py expects it).
          #data/twitter_training.csv already present in the repo
          #cp data/twitter_training.csv data/twitter_training.csv 
          echo "Data preparation complete. File copied to data/ directory." 

      # --- CD STAGE 1: Train Model ---
      - name: Run Model Training and Log to MLflow
        # This now executes successfully because NLTK data and the training file are in place.
        run: train_sentiment 
        
      # --- CD STAGE 2: Promote Model (Validation/Promotion Gate) ---
      - name: Run Model Promotion Logic
        # This now executes successfully because train_sentiment logged 'test_f1_macro' metric.
        run: python promote_model.py

      # --- CD STAGE 3: Build and Push Docker Image (Deployment Artifact) ---
      - name: Login to Docker Hub
        # Requires DOCKER_USERNAME and DOCKER_PASSWORD secrets to be set in GitHub.
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      - name: Build and Push Docker Image
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: ${{ secrets.DOCKER_USERNAME }}/ebay_mlops_sentiment:latest
          
      # --- CD STAGE 4: Deployment Trigger (Conceptual) ---
      - name: Deployment Trigger
        run: echo "Deployment trigger executed. Image pushed to registry."
        # In a real environment, this would contain the command to notify Kubernetes/Cloud service.